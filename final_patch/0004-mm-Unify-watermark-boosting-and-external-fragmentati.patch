From fb819998268e946ee87473d1aeaaf5679c12f5d9 Mon Sep 17 00:00:00 2001
From: Bharath Vedartham <linux.bhar@gmail.com>
Date: Thu, 11 Jul 2019 23:54:01 -0600
Subject: [PATCH 4/4] mm: Unify watermark boosting and external fragmentation
 prediction algorithm

In balance_pgdat, we unify watermark_boosting and the external fragmentation
detection algorithm. This is because the intent of both algorithms is the same, to reduce
external fragmentation by reclaiming a small amount of memory and then waking up kcompactd.

This "unification" is important as there a bunch of optimizations done during such balance_pgdat
runs like preventing suboptimal I/O and not making kswapd work too hard(by limiting the reclaim
priority to DEF_PRIORITY - 2)

Signed-off-by: Bharath Vedartham <linux.bhar@gmail.com>
---
 mm/vmscan.c | 78 +++++++++++++++++++++++++++++++++++++++++++------------------
 1 file changed, 55 insertions(+), 23 deletions(-)

diff --git a/mm/vmscan.c b/mm/vmscan.c
index ddf6a88..0be7dec 100644
--- a/mm/vmscan.c
+++ b/mm/vmscan.c
@@ -3574,6 +3574,8 @@ static int balance_pgdat(pg_data_t *pgdat, int order, int classzone_idx)
 	unsigned long nr_boost_reclaim;
 	unsigned long zone_boosts[MAX_NR_ZONES] = { 0, };
 	bool boosted;
+	bool potential_frag = 0;
+	bool need_compact;
 	struct zone *zone;
 	struct scan_control sc = {
 		.gfp_mask = GFP_KERNEL,
@@ -3599,9 +3601,25 @@ static int balance_pgdat(pg_data_t *pgdat, int order, int classzone_idx)
 
 		nr_boost_reclaim += zone->watermark_boost;
 		zone_boosts[i] = zone->watermark_boost;
+		
+		/*
+		 * Check if any of the zones could have a potential fragmentation event. 
+		 */
+		if (test_bit(ZONE_POTENTIAL_FRAG, &zone->flags)) {
+			potential_frag = 1;
+			clear_bit(ZONE_POTENTIAL_FRAG, &zone->flags);
+		}
 	}
 	boosted = nr_boost_reclaim;
 
+	/*
+	 * If kswapd is woken up because of watermark boosting or forced to run 
+	 * another balance_pgdat run because it detected an external fragmentation event,
+	 * we need to compact after reclaiming some pages. need_compact is true if such compaction
+	 * is required.
+	 */
+	need_compact = boosted || potential_frag;
+
 restart:
 	sc.priority = DEF_PRIORITY;
 	do {
@@ -3609,6 +3627,17 @@ static int balance_pgdat(pg_data_t *pgdat, int order, int classzone_idx)
 		bool raise_priority = true;
 		bool balanced;
 		bool ret;
+		/*
+		 * Kswapd can be called in 2 ways. One way is by exhausting the number of pages
+		 * below the watermarks. The other way is to reduce the amount of fragmentation.
+		 * Kswapd can be called when watermarks are boosted or be forced to run
+		 * balance_pgdat again when a zone is detected with a potential external
+		 * fragmentation event. If kswapd is running due to watermark boosting
+		 * or when an external fragmentation event is detected, we don't want to 
+		 * perform any suboptimal I/O or make kswapd work too hard. This is 
+		 * important from a performance point of view.
+		 */
+		bool defrag_run = nr_boost_reclaim || potential_frag;
 
 		sc.reclaim_idx = classzone_idx;
 
@@ -3634,39 +3663,41 @@ static int balance_pgdat(pg_data_t *pgdat, int order, int classzone_idx)
 		}
 
 		/*
-		 * If the pgdat is imbalanced then ignore boosting and preserve
-		 * the watermarks for a later time and restart. Note that the
-		 * zone watermarks will be still reset at the end of balancing
-		 * on the grounds that the normal reclaim should be enough to
-		 * re-evaluate if boosting is required when kswapd next wakes.
+		 * If the pgdat is imbalanced then ignore the deframentatio run. In
+		 * the case of watermark boosting, preserve the watermarks for 
+		 * a later time and restart. Note that the zone watermarks will
+		 * be still reset at the end of balancing on the grounds that the 
+		 * normal reclaim should be enough to re-evaluate if boosting is 
+		 * required when kswapd next wakes.
 		 */
 		balanced = pgdat_balanced(pgdat, sc.order, classzone_idx);
-		if (!balanced && nr_boost_reclaim) {
+		if (!balanced && defrag_run) {
 			nr_boost_reclaim = 0;
+			potential_frag = 0;
 			goto restart;
 		}
 
 		/*
-		 * If boosting is not active then only reclaim if there are no
+		 * If this is not a defrag run then only reclaim if there are no
 		 * eligible zones. Note that sc.reclaim_idx is not used as
 		 * buffer_heads_over_limit may have adjusted it.
 		 */
-		if (!nr_boost_reclaim && balanced)
+		if (!defrag_run && balanced)
 			goto out;
 
-		/* Limit the priority of boosting to avoid reclaim writeback */
-		if (nr_boost_reclaim && sc.priority == DEF_PRIORITY - 2)
+		/* Limit the priority of defrag_runs to avoid reclaim writeback */
+		if (defrag_run && sc.priority == DEF_PRIORITY - 2)
 			raise_priority = false;
 
 		/*
-		 * Do not writeback or swap pages for boosted reclaim. The
+		 * Do not writeback or swap pages for defragmentation runs. The
 		 * intent is to relieve pressure not issue sub-optimal IO
 		 * from reclaim context. If no pages are reclaimed, the
 		 * reclaim will be aborted.
 		 */
-		sc.may_writepage = !laptop_mode && !nr_boost_reclaim;
-		sc.may_swap = !nr_boost_reclaim;
-		sc.may_shrinkslab = !nr_boost_reclaim;
+		sc.may_writepage = !laptop_mode && !defrag_run;
+		sc.may_swap = !defrag_run;
+		sc.may_shrinkslab = !defrag_run;
 
 		/*
 		 * Do some background aging of the anon list, to give
@@ -3720,13 +3751,13 @@ static int balance_pgdat(pg_data_t *pgdat, int order, int classzone_idx)
 		 */
 		nr_reclaimed = sc.nr_reclaimed - nr_reclaimed;
 		nr_boost_reclaim -= min(nr_boost_reclaim, nr_reclaimed);
-
+		defrag_run = nr_boost_reclaim || potential_frag;
 		/*
-		 * If reclaim made no progress for a boost, stop reclaim as
+		 * If reclaim made no progress for a defragmentation run, stop reclaim as
 		 * IO cannot be queued and it could be an infinite loop in
 		 * extreme circumstances.
 		 */
-		if (nr_boost_reclaim && !nr_reclaimed)
+		if (defrag_run && !nr_reclaimed)
 			break;
 
 		if (raise_priority || !nr_reclaimed)
@@ -3751,17 +3782,18 @@ static int balance_pgdat(pg_data_t *pgdat, int order, int classzone_idx)
 			zone->watermark_boost -= min(zone->watermark_boost, zone_boosts[i]);
 			spin_unlock_irqrestore(&zone->lock, flags);
 		}
-
-		/*
-		 * As there is now likely space, wakeup kcompact to defragment
-		 * pageblocks.
-		 */
-		wakeup_kcompactd(pgdat, pageblock_order, classzone_idx);
 	}
+	
+	/*
+	 * As there is now likely space, wakeup kcompactd to defragment pageblocks.
+	 */
+	if (need_compact) 
+		wakeup_kcompactd(pgdat, pageblock_order, classzone_idx);
 
 	snapshot_refaults(NULL, pgdat);
 	__fs_reclaim_release();
 	psi_memstall_leave(&pflags);
+
 	/*
 	 * Return the order kswapd stopped reclaiming at as
 	 * prepare_kswapd_sleep() takes it into account. If another caller
-- 
1.8.3.1

